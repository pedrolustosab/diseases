{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.edge.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_edge_driver():\n",
    "    edge_options = Options()\n",
    "    edge_options.add_argument(\"--no-sandbox\")\n",
    "    edge_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    edge_options.add_argument(\"--headless\")\n",
    "    service = Service(r'C:/Users/PedroLustosa/OneDrive - Grupo Portfolio/Documentos/edgedriver_win64/msedgedriver.exe')\n",
    "    driver = webdriver.Edge(service=service, options=edge_options)\n",
    "    return driver\n",
    "\n",
    "def get_soup_xpath(url, xpath1, xpath2=None):\n",
    "    driver = None\n",
    "    soup = None\n",
    "    \n",
    "    # Tente encontrar o primeiro XPath\n",
    "    try:\n",
    "        driver = initialize_edge_driver()\n",
    "        driver.get(url)\n",
    "        element1 = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, xpath1))\n",
    "        )\n",
    "        if element1:\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            return soup\n",
    "    except:\n",
    "        pass\n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "            \n",
    "    # Tente encontrar o segundo XPath, se fornecido\n",
    "    if xpath2:\n",
    "        try:\n",
    "            driver = initialize_edge_driver()\n",
    "            driver.get(url)\n",
    "            element2 = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, xpath2))\n",
    "            )\n",
    "            if element2:\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, \"html.parser\")\n",
    "                links = soup.find_all('a', class_='bg-gray-l2 ds-8 border-0 rounded-0 mb-3 nav-btn nav-btn-horizontal mb-3 noLinking noDecoration card')\n",
    "                filtered_links = [f\"https://www.cdc.gov{link['href']}\" for link in links if 'illness' in link['href'] or 'symptoms' in link['href']]\n",
    "                href_list_card.extend(filtered_links)\n",
    "        except:\n",
    "            pass\n",
    "        finally:\n",
    "            if driver:\n",
    "                driver.quit()         \n",
    "    return soup\n",
    "\n",
    "def extract_text_by_class(soup, class_name):\n",
    "    if soup:\n",
    "        container = soup.find(class_=class_name)\n",
    "        if container:\n",
    "            elements = container.find_all(['h1', 'h2', 'h3', 'p', 'li', 'ul'])\n",
    "            text = '\\n'.join(element.get_text(strip=True) for element in elements)\n",
    "        else:\n",
    "            text = \"\"\n",
    "    else:\n",
    "        text = \"\"\n",
    "    return text\n",
    "\n",
    "def generate_text(prompt, model):\n",
    "    json_doencas = {}\n",
    "    if prompt:\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            response_text = response.text.replace(\"```\", \"\").replace(\"json\\n\", \"\").strip()\n",
    "            json_doencas = json.loads(response_text)\n",
    "        except json.JSONDecodeError as e:\n",
    "            pass\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    return json_doencas\n",
    "\n",
    "def configure_genai_model():\n",
    "    load_dotenv()\n",
    "    GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "    genai.configure(api_key=GEMINI_API_KEY)\n",
    "    generation_config = {\n",
    "        \"temperature\": 0.4,\n",
    "    }\n",
    "    safety_settings = {\n",
    "        'HATE': 'BLOCK_NONE',\n",
    "        'HARASSMENT': 'BLOCK_NONE',\n",
    "        'SEXUAL': 'BLOCK_NONE',\n",
    "        'DANGEROUS': 'BLOCK_NONE'\n",
    "    }\n",
    "    instruction = \"\"\"Você está atuando como um cientista de dados sênior. Sua tarefa é extrair informações sobre doenças e sintomas em português Brasil a partir do texto fornecido. Identifique e liste cada doença junto com seus sintomas associados conforme descrito no texto. Formate o resultado como um objeto JSON.\n",
    "\n",
    "    Especificações:\n",
    "    Identificação de Doenças: Enumere cada doença mencionada no texto.\n",
    "    Identificação de Sintomas: Para cada doença, liste os sintomas associados conforme descrito no texto.\n",
    "    Formato JSON: Organize as informações no formato JSON conforme o exemplo abaixo.\n",
    "\n",
    "    Exemplo de Formatação JSON:\n",
    "    {\n",
    "        \"HIV\": [\n",
    "            \"Febre\",\n",
    "            \"Calafrios\",\n",
    "            \"Rash\",\n",
    "            \"Suores noturnos (sudoração intensa durante o sono)\",\n",
    "            \"Dores musculares\",\n",
    "            \"Dor de garganta\",\n",
    "            \"Fadiga\",\n",
    "            \"Inchaço dos gânglios linfáticos\",\n",
    "            \"Úlceras na boca\"\n",
    "        ],\n",
    "        \"Mielite Flácida Aguda\": [\n",
    "            \"Fraqueza nos braços ou pernas\",\n",
    "            \"Perda de tônus muscular e reflexos\",\n",
    "            \"Queda ou fraqueza facial\",\n",
    "            \"Dificuldade para mover os olhos\",\n",
    "            \"Pálpebras caídas\",\n",
    "            \"Dificuldade para engolir\",\n",
    "            \"Dificuldade para falar\",\n",
    "            \"Dor nos braços, pernas, costas ou pescoço\"\n",
    "        ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-1.5-pro\",\n",
    "        generation_config=generation_config,\n",
    "        safety_settings=safety_settings,\n",
    "        system_instruction=instruction\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def save_to_json(data, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "def save_to_csv(file_name, data):\n",
    "    with open(file_name, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['URL'])\n",
    "        for item in data:\n",
    "            writer.writerow([item])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching:  76%|███████▋  | 39/51 [34:45<33:32, 167.72s/Links]  "
     ]
    }
   ],
   "source": [
    "# Configura o modelo\n",
    "model = configure_genai_model()\n",
    "\n",
    "# URL base\n",
    "base_url = 'https://www.cdc.gov/health-topics.html#A'\n",
    "xpath = '//*[@id=\"cdc-atozlist\"]/div/div[3]/div/ul/li[1]/a'\n",
    "\n",
    "# Obtém os links da página inicial\n",
    "soup = get_soup_xpath(base_url, xpath)\n",
    "link_hrefs = soup.select('#cdc-atozlist div div ul li a')\n",
    "save_to_csv('links.csv', link_hrefs)\n",
    "\n",
    "# Dicionário para armazenar informações de doenças\n",
    "doencas = {}\n",
    "href_list_card = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Itera pelos links e extrai informações\n",
    "for ref in tqdm(link_hrefs[:51], desc=\"Fetching\", unit=\"Links\"):\n",
    "    soup_link = get_soup_xpath(ref.get(\"href\"), '//*[@id=\"content\"]/div[1]','/html/body/div[4]/main/div[3]/div/div[4]/div/div[1]/div[2]')\n",
    "    texto = extract_text_by_class(soup_link, 'cdc-dfe-body__center')\n",
    "    json_doenca = generate_text(texto, model)\n",
    "    doencas.update(json_doenca)\n",
    "    time.sleep(5)\n",
    "\n",
    "# Salva \n",
    "save_to_json(doencas, 'doencas_cdc_50.json')\n",
    "save_to_csv('links_card_50.csv', href_list_card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_csv('links_card_50.csv', href_list_card)\n",
    "save_to_csv('links.csv', link_hrefs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
